{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GTI771 - Apprentissage machine avancé\n",
    "\n",
    "### Created: Thiago M. Paixão <br> Revised: Alessandro L. Koerich <br> Ver 1.0 <br> December 2020¶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NB2 - Template Matching Dataset Simpsons: using the mean image as prototype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will address the classification of characters from the TV serie \"The Simpson\" using the template matching technique. Instead of trying to match a query against every image in the training partition, the query is now compared against a representative prototype (mean image) of each class.\n",
    "\n",
    "The notebook is divided into four parts:\n",
    "\n",
    "- Setup\n",
    "- Train-test partitioning\n",
    "- Template matching-based classification using mean image\n",
    "- Performance evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import csv\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "# from skimage import data\n",
    "from skimage import io\n",
    "from skimage.transform import resize\n",
    "\n",
    "from utils import show, show_collection, load_simpsons_dataset, resize_dataset, classify_template_matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# change this to the path where the dataset is located in your filesystem\n",
    "DATASET_PATH = '../data/Simpsons-Train-Valid'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and resize the Simpsons dataset\n",
    "\n",
    "As in the NB1, the dataset (partitioned into training and test splits) are loaded and resized. Loading and resize functionalities are, now, implemented in ``utils.py``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_set, test_set = load_simpsons_dataset(DATASET_PATH)\n",
    "train_set_resized = resize_dataset(train_set, output_shape=(256, 256))\n",
    "test_set_resized = resize_dataset(test_set, output_shape=(256, 256))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the prototypes (mean images)\n",
    "\n",
    "The function bellow computes the mean image for each class in a dataset. The result is dictionary that maps from labels to images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def mean_image(dataset):\n",
    "    zero_arr = np.zeros_like(dataset[0][0], dtype=np.float32)\n",
    "    counter = defaultdict(lambda: 0)\n",
    "    accumulator = defaultdict(lambda: zero_arr.copy())\n",
    "    for image, label in dataset:\n",
    "        counter[label] += 1\n",
    "        accumulator[label] += image\n",
    "    for label in accumulator:\n",
    "        accumulator[label] = (accumulator[label] / counter[label])\n",
    "    mean_images_dataset = [(image, label) for label, image in accumulator.items()]\n",
    "    return mean_images_dataset\n",
    "\n",
    "prototypes = mean_image(train_set_resized)\n",
    "\n",
    "# show the mean images (prototypes)\n",
    "labels = [label for _, label in prototypes]\n",
    "images = [prototype for prototype, _ in prototypes]\n",
    "show_collection(images, labels, scale=0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Template matching-based classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_query, label_query = random.choice(test_set_resized)\n",
    "image_result, label_result = classify_template_matching(image_query, prototypes)\n",
    "\n",
    "titles = ['query = {}'.format(label_query), 'result = {}'.format(label_result)]\n",
    "images = [image_query, image_result]\n",
    "show_collection(images, titles, scale=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance evaluation\n",
    "\n",
    "Compute some performance metrics on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Evaluation metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the mentioned ``sklearn`` metrics, we first encode the labels ('bart', 'homer', ...) to numeric values ranging from $0$ to $n_{classes} - 1$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "# building encoder\n",
    "labels_train = [label for _, label in train_set_resized]\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "label_encoder.fit(labels_train)\n",
    "\n",
    "# encoding the labels of the test set\n",
    "labels_test = [label for _, label in test_set_resized]\n",
    "y_true = label_encoder.transform(labels_test)\n",
    "\n",
    "print('True labels')\n",
    "for label, y in zip(labels_test, y_true):\n",
    "    print('{} -> {}'.format(label, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting the labels of the test set (remember that the test set has a single exemplar of each class):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels = []\n",
    "for image_query, _ in test_set_resized:\n",
    "    _, label = classify_template_matching(image_query, prototypes)\n",
    "    labels.append(label)\n",
    "y_pred = label_encoder.transform(labels)\n",
    "\n",
    "print('Predicted labels')\n",
    "for label, y in zip(labels_test, y_pred):\n",
    "    print('{} -> {}'.format(label, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can compute the metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_true, y_pred)\n",
    "print('Correct classification rate for the training dataset = {:.2f}%'.format(100 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "report = classification_report(y_true, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe the warning above. This is due to zero division in the F1 metric calculation, which occurs when precision and recall are simultaneoulsy zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
