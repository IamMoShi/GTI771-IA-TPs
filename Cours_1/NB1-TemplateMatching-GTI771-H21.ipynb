{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GTI771 - Apprentissage machine avancé\n",
    "\n",
    "### Created: Thiago M. Paixão <br> Revised: Alessandro L. Koerich <br> Ver 1.0 <br> December 2020¶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NB1 - Template Matching Dataset Simpsons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will address the classification of characters from the TV serie \"The Simpson\" using a naive template matching technique. The notebook is divided into four parts:\n",
    "\n",
    "- Setup\n",
    "- Train-test partitioning\n",
    "- Template matching-based classification\n",
    "- Performance evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import csv\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from skimage import io\n",
    "from skimage.transform import resize\n",
    "\n",
    "from utils import show, show_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# change this to the path where the dataset is located in your filesystem\n",
    "# DATASET_PATH = '/mnt/data/datasets/Simpsons-Train-Valid' \n",
    "DATASET_PATH = 'Simpsons-Train-Valid' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test partitioning\n",
    "\n",
    "Here, we split the entire collection into two train and test datasets. Each dataset has the for\n",
    "\n",
    "$$ \\mathcal{X} = \\{({\\bf x}^t, r^t)\\}_{t=1}^n $$,\n",
    "\n",
    "where ${\\bf x}^t$ denotes the $t$-th image and $r^t$ its respective character name (i.e., the class label). To accomplish this, we first create a dictionary ``map_character_filenames`` that maps characters to file names in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# list all valid filenames\n",
    "filenames = glob.glob(os.path.join(DATASET_PATH, 'Train', '*'))\n",
    "filenames = [filename for filename in filenames if 'Thumbs.db' not in filename] # remove Thumbs.db\n",
    "\n",
    "# create the mapping\n",
    "map_character_filenames = defaultdict(list)\n",
    "for filename in filenames:\n",
    "    basename = os.path.splitext(os.path.basename(filename))[0]\n",
    "    character = basename[: -3] # remove the ending digits\n",
    "    map_character_filenames[character].append(filename)\n",
    "                                    \n",
    "# check how many samples (images) are available for each class (character)\n",
    "for character, filenames in map_character_filenames.items():\n",
    "    print('{} = {} samples'.format(character, len(filenames)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test set is constructed by randomly selecting one exemplar of each class. The train, on its turn, comprises all the pairs $({\\bf x}^t, r^t)$ of the dataset except those in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_set = []\n",
    "test_set = []\n",
    "for character in map_character_filenames:\n",
    "    # select randomly 1 sample to the test set\n",
    "    filename_chosen = random.choice(map_character_filenames[character])\n",
    "    image = io.imread(filename_chosen)\n",
    "    test_set.append((image, character))\n",
    "    \n",
    "    # the rest of the samples are assigned to the train set\n",
    "    for filename in map_character_filenames[character]:\n",
    "        if filename != filename_chosen:\n",
    "            image = io.imread(filename)\n",
    "            train_set.append((image, character))\n",
    "\n",
    "# show images\n",
    "titles = [character for _, character in test_set]\n",
    "images = [image for image, _ in test_set]\n",
    "show_collection(images, titles, scale=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As our template matching plays direct pixel comparison, we must resize the images so that they have the same dimensions (shape). For this example, it was chosen the shape ``(256, 256)``.\n",
    "\n",
    "**Note:** *The ``resize`` function of the scikit-image library has a side effect of converting images to float in the range $[0,1]$.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def resize_dataset(dataset, output_shape=(200, 200)):\n",
    "    dataset_resized = []\n",
    "    for image, character in dataset:\n",
    "        image_resized = resize(image, output_shape)\n",
    "        dataset_resized.append((image_resized, character))\n",
    "    return dataset_resized\n",
    "\n",
    "train_set_resized = resize_dataset(train_set, output_shape=(256, 256))\n",
    "test_set_resized = resize_dataset(test_set, output_shape=(256, 256))\n",
    "\n",
    "titles = [character for _, character in test_set_resized]\n",
    "images = [image for image, _ in test_set_resized]\n",
    "show_collection(images, titles, scale=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Template matching-based classification\n",
    "\n",
    "To proceed with the classification, we randomly select a query image ($Q$) from the test set and search for the most similar image ($S$) in the training set as follows:\n",
    "\n",
    "$$S = \\operatorname{argmin}_{i}|Q - {\\bf x}_i|_2.$$\n",
    "\n",
    "Ideally, the class/character of $S$ should match $Q$'s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def classify(image_query, train_set):\n",
    "    min_cost = float('inf')\n",
    "    label_result = ''\n",
    "    image_result = None\n",
    "    \n",
    "    for image_candidate, label_candidate in train_set:\n",
    "        cost = ((image_query - image_candidate) ** 2).sum()\n",
    "        if cost < min_cost:\n",
    "            min_cost = cost\n",
    "            label_result = label_candidate\n",
    "            image_result = image_candidate\n",
    "    return image_result, label_result\n",
    "    \n",
    "image_query, label_query = random.choice(test_set_resized)\n",
    "image_result, label_result = classify(image_query, train_set_resized)\n",
    "\n",
    "titles = ['query = {}'.format(label_query), 'result = {}'.format(label_result)]\n",
    "images = [image_query, image_result]\n",
    "show_collection(images, titles, scale=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance evaluation\n",
    "\n",
    "Compute some performance metrics on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Evaluation metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the mentioned ``sklearn`` metrics, we first encode the labels ('bart', 'homer', ...) to numeric values ranging from $0$ to $n_{classes} - 1$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "# building encoder\n",
    "labels_train = [label for _, label in train_set_resized]\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "label_encoder.fit(labels_train)\n",
    "\n",
    "# encoding the labels of the test set\n",
    "labels_test = [label for _, label in test_set_resized]\n",
    "y_true = label_encoder.transform(labels_test)\n",
    "\n",
    "print('True labels')\n",
    "for label, y in zip(labels_test, y_true):\n",
    "    print('{} -> {}'.format(label, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting the labels of the test set (remember that the test set has a single exemplar of each class):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels = []\n",
    "for image_query, _ in test_set_resized:\n",
    "    _, label = classify(image_query, train_set_resized)\n",
    "    labels.append(label)\n",
    "y_pred = label_encoder.transform(labels)\n",
    "\n",
    "print('Predicted labels')\n",
    "for label, y in zip(labels_test, y_pred):\n",
    "    print('{} -> {}'.format(label, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can compute the metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_true, y_pred)\n",
    "print('Correct classification rate for the training dataset = {:.2f}%'.format(100 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "report = classification_report(y_true, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe the warning above. This is due to zero division in the F1 metric calculation, which occurs when precision and recall are simultaneoulsy zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suggested activity\n",
    "\n",
    "Although performance evaluation should be performed on the test set, evaluation on the training set can be useful for a 'sanity test' of the implementation. In our case, we know that template matching-based classification is expected to fully recover the queries if they are fom the training partition.\n",
    "\n",
    "Based on this fact, we suggest to verify this yourself by running the above metrics on the training partition."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
