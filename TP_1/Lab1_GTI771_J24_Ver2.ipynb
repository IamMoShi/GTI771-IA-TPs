{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/IamMoShi/GTI771-IA-TPs/blob/main/Lab1_GTI771_J24_Ver2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sjgFUch8bLwE"
   },
   "source": [
    "# GTI771 - Apprentissage machine avancé\n",
    "## Département de génie logiciel et des technologies de l’information (LogTI)\n",
    "\n",
    "\n",
    "\n",
    "## Laboratoire 1 - Préparation des données\n",
    "#### <font color=black> Version 2 - Janvier 2024 </font>\n",
    "\n",
    "##### <font color=grey> Version 1 - Prof. Alessandro L. Koerich.\n",
    "##### Version 2 - Chargé de lab. Arthur Josi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1G_KivoknmxT"
   },
   "source": [
    "Les laboratoires sont à faire par groupe de deux ou trois étudiants. Favorisez les groupes de trois."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eSx7LnYLbLwG"
   },
   "source": [
    "| NOMS                  | CODE PERMANENT                                   |\n",
    "|-----------------------|--------------------------------------------------|\n",
    "| Étudiant1             | Code1                                            |\n",
    "| Étudiant2             | Code2                                            |\n",
    "| Étudiant3             | Code3                                            |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EuR8ueyebLwG"
   },
   "source": [
    "# Introduction\n",
    "\n",
    "Ce premier laboratoire porte sur la préparation de données pour l'apprentissage machine. Le problème de classification qui vous est présenté est le problème [Facial Expression Recognition (FER)](https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge/data), dont le but est de classer des visages dans sept catégories.\n",
    "\n",
    "Veuillez noter que les images qui vous sont fournies ne sont pas nécessairement très faciles à travailler. Plusieurs images comportent du bruit, des artéfacts ou des éléments non pertinents. Le défi de ce laboratoire repose sur cette difficulté qui est chose courante dans les problèmes d’apprentissage machine moderne.\n",
    "\n",
    "Voici, en exemple, des images de visages se retrouvant dans l’ensemble de données:\n",
    "\n",
    "![Exemples de FER](https://miro.medium.com/max/2420/1*nXqJ4lMiBRp4Ilm3bpRxuA.png)\n",
    "\n",
    "L’évaluation de ce laboratoire sera basée sur:\n",
    "- la qualité des algorithmes proposés et utilisés;\n",
    "- les réponses aux questions dans ce notebook;\n",
    "- l'organisation de votre code source (SVP, n'oubliez pas de mettre des commentaires dans le code source!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "nb5c_PGPbLwG",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# Modules et bibliotèques python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yPZudkRhbLwG"
   },
   "source": [
    "### Import de bibliotèques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CNG3ZDNYbLwG"
   },
   "source": [
    "###  <font color=blue> À faire: </font>\n",
    "N'oubliez pas d'ajouter une courte description aux bibliothèques que vous allez utiliser pour compléter ce notebook."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VbrNGp9ZD7Xo",
    "outputId": "d1f75bea-2882-4f85-be0d-a54a6f1b881f",
    "ExecuteTime": {
     "end_time": "2025-05-14T19:23:12.027245Z",
     "start_time": "2025-05-14T19:23:12.020358Z"
    }
   },
   "source": "# !pip install imagehash facenet_pytorch",
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 376
    },
    "executionInfo": {
     "elapsed": 35,
     "status": "error",
     "timestamp": 1747247467891,
     "user": {
      "displayName": "Léo FORNOFF",
      "userId": "08948551382045981836"
     },
     "user_tz": 240
    },
    "id": "UqWHnNHmbLwH",
    "outputId": "472b4039-a416-4f95-821d-0f436c0862cc",
    "ExecuteTime": {
     "end_time": "2025-05-14T19:45:44.315376Z",
     "start_time": "2025-05-14T19:45:43.985551Z"
    }
   },
   "source": [
    "import numpy as np  # package for scientific computing with Python.\n",
    "import matplotlib.pyplot as plt  # 2D plotting library\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import imagehash"
   ],
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Error importing numpy: you should not try to import numpy from\n        its source directory; please exit the numpy source tree, and relaunch\n        your python interpreter from there.",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mImportError\u001B[39m                               Traceback (most recent call last)",
      "\u001B[36mFile \u001B[39m\u001B[32mH:\\Shared drives\\GTI771_IA\\GTI771-IA-TPs\\.venv\\Lib\\site-packages\\numpy\\__init__.py:127\u001B[39m\n\u001B[32m    126\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m127\u001B[39m     \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mnumpy\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m__config__\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m show_config\n\u001B[32m    128\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "\u001B[31mImportError\u001B[39m: cannot import name 'show_config' from 'numpy.__config__' (H:\\Shared drives\\GTI771_IA\\GTI771-IA-TPs\\.venv\\Lib\\site-packages\\numpy\\__config__.py)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[31mImportError\u001B[39m                               Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[2]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mnumpy\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mnp\u001B[39;00m  \u001B[38;5;66;03m# package for scientific computing with Python.\u001B[39;00m\n\u001B[32m      2\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mmatplotlib\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mpyplot\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mplt\u001B[39;00m  \u001B[38;5;66;03m# 2D plotting library\u001B[39;00m\n\u001B[32m      3\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mcv2\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mH:\\Shared drives\\GTI771_IA\\GTI771-IA-TPs\\.venv\\Lib\\site-packages\\numpy\\__init__.py:132\u001B[39m\n\u001B[32m    128\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    129\u001B[39m     msg = \u001B[33m\"\"\"\u001B[39m\u001B[33mError importing numpy: you should not try to import numpy from\u001B[39m\n\u001B[32m    130\u001B[39m \u001B[33m    its source directory; please exit the numpy source tree, and relaunch\u001B[39m\n\u001B[32m    131\u001B[39m \u001B[33m    your python interpreter from there.\u001B[39m\u001B[33m\"\"\"\u001B[39m\n\u001B[32m--> \u001B[39m\u001B[32m132\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m(msg) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01me\u001B[39;00m\n\u001B[32m    134\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m _core\n\u001B[32m    135\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_core\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[32m    136\u001B[39m     False_, ScalarType, True_,\n\u001B[32m    137\u001B[39m     \u001B[38;5;28mabs\u001B[39m, absolute, acos, acosh, add, \u001B[38;5;28mall\u001B[39m, allclose,\n\u001B[32m   (...)\u001B[39m\u001B[32m    182\u001B[39m     vecmat, void, vstack, where, zeros, zeros_like\n\u001B[32m    183\u001B[39m )\n",
      "\u001B[31mImportError\u001B[39m: Error importing numpy: you should not try to import numpy from\n        its source directory; please exit the numpy source tree, and relaunch\n        your python interpreter from there."
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rsy-BvW3bLwH"
   },
   "source": [
    "# Partie 1 - Analyse exploratoire des données\n",
    "\n",
    "On va commencer par regarder les données, c'est une pratique indispensable.\n",
    "\n",
    "Pour ce lab, nous allons utiliser le dataset Facial Emotion Recognition (FER).\n",
    "\n",
    "L'ensemble de données est disponible dans Moodle. Il contient presque 35,000 images de visages, avec une résolution de 48$\\times$48 pixels en niveau de gris.\n",
    "\n",
    "Les images se trouvent dans un fichier csv sous la forme d’un vecteur de 2,304 scalaires avec des valeurs entre 0 et 255.\n",
    "\n",
    "Les partitions apprentissage, validation et test sont déjà préétablies.\n",
    "\n",
    "Format du fichier: Emotion,Pixels,Usage avec:\n",
    "- Emotion:  integer [0, 6]\n",
    "- Pixels:   integer [0, 255]\n",
    "- Usage:    string [Training, PublicTest, PrivateTest]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NfrgTZ-jbLwI"
   },
   "source": [
    "## Charger le fichier de données"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1747247392402,
     "user": {
      "displayName": "Léo FORNOFF",
      "userId": "08948551382045981836"
     },
     "user_tz": 240
    },
    "id": "7SjPjCNoseu4"
   },
   "source": [
    "# from google.colab import files\n",
    "# uploaded = files.upload()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "1X9PDGfruoSO"
   },
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 561
    },
    "id": "UdCmTZ-hbLwI",
    "outputId": "2eb2a58e-7ef0-44ac-8421-bfca7d47cb85"
   },
   "source": [
    "# Load data\n",
    "ferData = np.loadtxt('content/fer2013.csv', delimiter=',', dtype=str)\n",
    "\n",
    "# Training partition\n",
    "Xtrain = np.ones((28709, 2304), float)\n",
    "\n",
    "for i in range(1, 28710):\n",
    "    Xtrain[i - 1] = ferData[i, 1].split(\" \")\n",
    "\n",
    "ytrain = ferData[1:28710, 0].astype(int)\n",
    "\n",
    "# Validation partition\n",
    "Xval = np.ones((3589, 2304), float)\n",
    "\n",
    "for i in range(28710, 32299):\n",
    "    Xval[i - 28710] = ferData[i, 1].split(\" \")\n",
    "\n",
    "yval = ferData[28710:32299, 0].astype(int)\n",
    "\n",
    "# Test partition\n",
    "Xtest = np.ones((3589, 2304), float)\n",
    "\n",
    "for i in range(32299, 35887):\n",
    "    Xtest[i - 32299] = ferData[i, 1].split(\" \")\n",
    "\n",
    "ytest = ferData[32299:, 0].astype(int)\n",
    "\n",
    "print(Xtrain.shape, Xval.shape, Xtest.shape)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "NhwicuG-bLwI",
    "outputId": "3616812c-9215-4242-d128-69b35c9f1511"
   },
   "source": [
    "# Reshape les vecteurs de 2,304 dimensions vers matrices 48x48\n",
    "# Afin d'avoir [samples][channels][width][height]\n",
    "\n",
    "Xtrain = Xtrain.reshape(Xtrain.shape[0], 1, 48, 48).astype('uint8')\n",
    "Xtest = Xtest.reshape(Xtest.shape[0], 1, 48, 48).astype('uint8')\n",
    "Xval = Xval.reshape(Xval.shape[0], 1, 48, 48).astype('uint8')\n",
    "\n",
    "print(Xtrain.shape, Xval.shape, Xtest.shape)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-OuwIsZObLwI"
   },
   "source": [
    "## <font color=black> 1a: Visualisation des images de visages </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CyUZbsrybLwI"
   },
   "source": [
    "###  <font color=blue> À faire: </font>\n",
    "\n",
    "1. Créer une grille de dimension 7 lignes $\\times$ $4$ colones avec des images de visage prises aleatoirement dans l'ensemble de apprentissage. Montrer une catégorie dans chaque ligne.\n",
    "\n",
    "Vous pouvez visualiser les images en utilisant `plt.imshow`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bMRJxBtpDu7A"
   },
   "source": [
    "---\n",
    "** Code ajouté **"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "vgZgFvmMbLwI",
    "outputId": "928f60df-f9ad-4f6d-ed61-e90f398bcec4"
   },
   "source": [
    "# Votre code ici\n",
    "num_classes = 7\n",
    "images_per_class = 4\n",
    "\n",
    "emotion_labels = [\"Colère\", \"Dégoût\", \"Peur\", \"Joie\", \"Tristesse\", \"Surprise\",\n",
    "                  \"Neutre\"]\n",
    "\n",
    "fig, ax = plt.subplots(num_classes, images_per_class, figsize=(10, 15))\n",
    "\n",
    "for class_id in range(num_classes):\n",
    "    # Select only ids corresponding to the searched class\n",
    "    idxs = np.where(ytrain == class_id)[0]\n",
    "    selected = np.random.choice(idxs, images_per_class, replace=False)\n",
    "\n",
    "    for j, img_idx in enumerate(selected):\n",
    "        ax[class_id, j].imshow(Xtrain[img_idx, 0], cmap='gray')\n",
    "        ax[class_id, j].axis('off')\n",
    "\n",
    "        if j == 0:\n",
    "            ax[class_id, j].set_ylabel(emotion_labels[class_id], fontsize=12,\n",
    "                                       rotation=0, labelpad=50, va='center')\n",
    "\n",
    "plt.suptitle(\"Images aléatoires par classe (1 ligne = 1 classe)\", fontsize=16)\n",
    "plt.subplots_adjust(left=0.2, hspace=0.4, top=0.93)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fZbKfKqEDu7A"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zov3P0A_bLwI"
   },
   "source": [
    "## 1b: Statistiques des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jB7A3jjXbLwI"
   },
   "source": [
    "Est-ce que vous avez un ensemble de données balancé? C.-à-d., une distribution égalitaire d’exemples par classe?\n",
    "\n",
    "###  <font color=blue> À faire: </font>\n",
    "\n",
    "1. Montrer les histogrammes de distribution des données pour les partitions de validation et test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "30s0INznbLwI"
   },
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "uTH-ZdIYwHg0",
    "outputId": "e290c3c3-8ef5-4cf7-ef12-fcda11bf2f29"
   },
   "source": [
    "labels = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
    "\n",
    "\n",
    "def plot_class_histogram(y, title):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.hist(y, bins=np.arange(8) - 0.5,\n",
    "            edgecolor='black')  # 7 bins: [-0.5, 0.5, ..., 6.5]\n",
    "\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Class\")\n",
    "    ax.set_ylabel(\"Number of examples\")\n",
    "\n",
    "    # Met les noms de classe sous les barres\n",
    "    ax.set_xticks(range(7))\n",
    "    ax.set_xticklabels(labels, rotation=45, ha='right')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Tracer les 3 histogrammes\n",
    "plot_class_histogram(ytrain, \"Distribution of classes - Training\")\n",
    "plot_class_histogram(yval, \"Distribution of classes - Validation\")\n",
    "plot_class_histogram(ytest, \"Distribution of classes - Test\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nA7XzrAfbLwI"
   },
   "source": [
    "# Partie 2 - Préparation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NZ43VPmNbLwI"
   },
   "source": [
    "## 2a: Nettoyage et normalisation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BeIyURjjbLwI"
   },
   "source": [
    "Avant de passer à d'autres étapes, vous devez vous assurer que il n'y a pas de:\n",
    "- données abberantes;\n",
    "- valeurs manquantes;\n",
    "- valeurs inapplicables ou aberrantes;\n",
    "- etc.   \n",
    "\n",
    "###  <font color=blue> À faire: </font>\n",
    "\n",
    "1. Concevoir un algorithme pour vérifier l'intégrité des données, faire des corrections si nécessaires, et finalement, normaliser les données dans la plage [0, 1].\n",
    "2. Appliquer sur les ensembles d’apprentissage et validation. Attention! Étant donné que les données de l'ensemble de test sont considérées \"inconnues\" préalablement, il faut bien réfléchir quoi faire avec ces données.\n",
    "3. Générer un fichier *fer2013-clean.csv* (même format) avec les données nettoyées et normalisées.\n",
    "\n",
    "4. Décrire les étapes de votre algorithme/code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FlMIVtypbLwJ"
   },
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KQ_oQjanDu7E"
   },
   "source": [
    "---\n",
    "#### Intégrité des données"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "IdQsDBLTbLwJ"
   },
   "source": [
    "# Check if there is NaN values in the data\n",
    "assert not np.isnan(Xtrain).any(), \"NaN détecté dans Xtrain\"\n",
    "assert not np.isnan(Xval).any(), \"NaN détecté dans Xval\"\n",
    "assert not np.isnan(Xtest).any(), \"NaN détecté dans Xtest\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Arf9pqbFDu7E"
   },
   "source": [
    "# Format checking\n",
    "assert Xtrain.shape[1:] == (1, 48,\n",
    "                            48), f\"Xtrain shape incorrect: {Xtrain.shape}\"\n",
    "assert Xval.shape[1:] == (1, 48, 48), f\"Xval shape incorrect: {Xval.shape}\"\n",
    "assert Xtest.shape[1:] == (1, 48, 48), f\"Xtest shape incorrect: {Xtest.shape}\"\n",
    "\n",
    "assert Xtrain.dtype == np.uint8\n",
    "assert Xtrain.min() >= 0 and Xtrain.max() <= 255\n",
    "\n",
    "assert Xval.dtype == np.uint8\n",
    "assert Xval.min() >= 0 and Xval.max() <= 255\n",
    "\n",
    "assert Xtest.dtype == np.uint8\n",
    "assert Xtest.min() >= 0 and Xtest.max() <= 255"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gjc1gXxkDu7F"
   },
   "source": [
    "---\n",
    "#### Données abérrantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2LdlMulsDu7F"
   },
   "source": [
    "**Affichage**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "nVw312guDu7F"
   },
   "source": [
    "def show_examples_grid(images, indices, title, max_samples=5):\n",
    "    if len(indices) == 0:\n",
    "        print(f\"Aucune image détectée comme {title.lower()}.\")\n",
    "        return\n",
    "\n",
    "    print(\n",
    "        f\"\\n{len(indices)} images détectées comme {title.lower()}.\\nAffichage des {min(len(indices), max_samples)} premières :\")\n",
    "\n",
    "    fig, axs = plt.subplots(1, min(len(indices), max_samples), figsize=(12, 2))\n",
    "    fig.suptitle(title)\n",
    "    for i, idx in enumerate(indices[:max_samples]):\n",
    "        axs[i].imshow(images[idx], cmap='gray')\n",
    "        axs[i].set_title(f\"idx {idx}\")\n",
    "        axs[i].axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def show_duplicates_grid(images, duplicates, max_samples=3):\n",
    "    if len(duplicates) == 0:\n",
    "        print(\"Aucun doublon détecté.\")\n",
    "        return\n",
    "\n",
    "    print(\n",
    "        f\"\\n{len(duplicates)} doublons détectés.\\nAffichage des {min(len(duplicates), max_samples)} paires :\")\n",
    "\n",
    "    fig, axs = plt.subplots(len(duplicates[:max_samples]), 2,\n",
    "                            figsize=(6, 2 * max_samples))\n",
    "    for i, (idx1, idx2) in enumerate(duplicates[:max_samples]):\n",
    "        axs[i, 0].imshow(images[idx1], cmap='gray')\n",
    "        axs[i, 0].set_title(f\"Image {idx1}\")\n",
    "        axs[i, 0].axis('off')\n",
    "\n",
    "        axs[i, 1].imshow(images[idx2], cmap='gray')\n",
    "        axs[i, 1].set_title(f\"Doublon {idx2}\")\n",
    "        axs[i, 1].axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qohl_l5LDu7F"
   },
   "source": [
    "**Seuils**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "eei1RlvQDu7G"
   },
   "source": [
    "# determined by manually testing\n",
    "THRESHOLD_DARK = 50\n",
    "THRESHOLD_BRIGHT = 200\n",
    "THRESHOLD_BLUR = 200.0"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L6Sdi4qpDu7G"
   },
   "source": [
    "**Tests pour déterminer les seuils**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "o5ZhAuuuDu7G",
    "outputId": "ee9bb7b7-1afa-4f07-c2a4-6eadff86c465"
   },
   "source": [
    "variances = []\n",
    "for img in Xtrain[:, 0]:  # shape (N, 48, 48)\n",
    "    var = cv2.Laplacian(img, cv2.CV_64F).var()\n",
    "    variances.append(var)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(variances, bins=50)\n",
    "plt.title(\"Distribution de la netteté (Variance du Laplacien)\")\n",
    "plt.xlabel(\"Variance\")\n",
    "plt.ylabel(\"Nombre d'images\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "lHwg48HVDu7G",
    "outputId": "9ad13701-1427-421e-b797-9cb903cf5cb6"
   },
   "source": [
    "# Calculate the variance for each image\n",
    "laplacian_variances = []\n",
    "indices_above_4000 = []\n",
    "\n",
    "for idx, img in enumerate(Xtrain[:, 0]):  # images shape (N, 48, 48)\n",
    "    var = cv2.Laplacian(img, cv2.CV_64F).var()\n",
    "    laplacian_variances.append(var)\n",
    "    if var < 200:\n",
    "        indices_above_4000.append((idx, var))\n",
    "\n",
    "# Show the detected images\n",
    "max_samples = min(5, len(indices_above_4000))\n",
    "if max_samples == 0:\n",
    "    print(\"No image with sharpness greater than 4000\")\n",
    "else:\n",
    "    print(f\"{len(indices_above_4000)} images with sharpness> 4000\")\n",
    "    for i in range(max_samples):\n",
    "        idx, var = indices_above_4000[i]\n",
    "        plt.imshow(Xtrain[idx][0], cmap='gray')\n",
    "        plt.title(f\"idx={idx} — sharpness={var:.2f}\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kAmyxb50Du7H"
   },
   "source": [
    "**Fonctions de vérification**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "m2AzJg-oDu7H"
   },
   "source": [
    "def check_brightness(images):\n",
    "    too_dark, too_bright = [], []\n",
    "    for idx, img in enumerate(images):\n",
    "        mean_val = img.mean()\n",
    "        if mean_val < THRESHOLD_DARK:\n",
    "            too_bright.append(idx)\n",
    "        elif mean_val > THRESHOLD_BRIGHT:\n",
    "            too_dark.append(idx)\n",
    "    return too_dark, too_bright\n",
    "\n",
    "\n",
    "def check_blurriness(images):\n",
    "    blurry = []\n",
    "    for idx, img in enumerate(images):\n",
    "        laplacian_var = cv2.Laplacian(img, cv2.CV_64F).var()\n",
    "        if laplacian_var < THRESHOLD_BLUR:\n",
    "            blurry.append(idx)\n",
    "    return blurry\n",
    "\n",
    "\n",
    "def find_duplicates(images, hashfunc=imagehash.phash):\n",
    "    seen = {}\n",
    "    duplicates = []\n",
    "    for idx, img in enumerate(images):\n",
    "        pil_img = Image.fromarray(img)\n",
    "        img_hash = hashfunc(pil_img)\n",
    "        if img_hash in seen:\n",
    "            duplicates.append((seen[img_hash], idx))\n",
    "        else:\n",
    "            seen[img_hash] = idx\n",
    "    return duplicates"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "vWM9BSdMDu7H",
    "outputId": "309703e5-9159-4773-e398-3d338e7d6835"
   },
   "source": [
    "# 1. Applati la dimension \"channel\"\n",
    "Xtrain_images = Xtrain[:, 0]  # (n, 48, 48)\n",
    "\n",
    "# 2. Exécute les détections\n",
    "too_dark, too_bright = check_brightness(Xtrain_images)\n",
    "blurry = check_blurriness(Xtrain_images)\n",
    "dupes = find_duplicates(Xtrain_images)\n",
    "\n",
    "# 3. Affiche les grilles organisées\n",
    "show_examples_grid(Xtrain_images, too_dark, \"Images trop sombres\")\n",
    "show_examples_grid(Xtrain_images, too_bright, \"Images trop claires\")\n",
    "show_examples_grid(Xtrain_images, blurry, \"Images floues\")\n",
    "show_duplicates_grid(Xtrain_images, dupes)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jztJlf88Du7H"
   },
   "source": [
    "**Elimination des images qui ne sont pas des visages**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VUAroy3EDu7I"
   },
   "source": [
    "Tentative avec openCV"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "2maHVyScDu7I"
   },
   "source": [
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "o8SCpTY2Du7I"
   },
   "source": [
    "def preprocess_contrast(img):\n",
    "    return cv2.equalizeHist(img)\n",
    "\n",
    "def detect_faces(images, min_neighbors=3):\n",
    "    detected_faces = []\n",
    "    no_faces = []\n",
    "\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "    for idx, img in enumerate(images):\n",
    "        # S'assurer que l'image est en uint8 et 48x48\n",
    "        img_uint8 = img.astype(np.uint8)\n",
    "        img_eq = preprocess_contrast(img_uint8)\n",
    "        img_resized = cv2.resize(img_eq, (96, 96), interpolation=cv2.INTER_LINEAR)\n",
    "        faces = face_cascade.detectMultiScale(img_resized, scaleFactor=1.1, minNeighbors=3)\n",
    "\n",
    "\n",
    "        if len(faces) > 0:\n",
    "            detected_faces.append(idx)\n",
    "        else:\n",
    "            no_faces.append(idx)\n",
    "\n",
    "    return detected_faces, no_faces\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "UVc0v-D4Du7I",
    "outputId": "54f1ea99-ab36-4894-887c-dcb64c651c4b"
   },
   "source": [
    "Xtrain_images = Xtrain[:, 0]  # (n, 48, 48)\n",
    "# has_face, no_face = detect_faces(Xtrain_images)\n",
    "\n",
    "# print(f\"{len(no_face)} images sans visage détecté\")\n",
    "\n",
    "# Affiche les images à supprimer (optionnel)\n",
    "# show_examples_grid(Xtrain_images, no_face, \"Images sans visage détecté\", max_samples=5)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "lx-DWWIMDu7J"
   },
   "source": [
    "def get_middle_line(img):\n",
    "    h = img.shape[0]\n",
    "    return img[h // 2, :]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "A1enLzL4Du7J"
   },
   "source": [
    "def plot_middle_line(img):\n",
    "    line = get_middle_line(img)\n",
    "    plt.figure(figsize=(6, 2))\n",
    "    plt.plot(line)\n",
    "    plt.title(\"Profil de la ligne médiane (niveaux de gris)\")\n",
    "    plt.xlabel(\"Colonne (x)\")\n",
    "    plt.ylabel(\"Intensité (0-255)\")\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "xcr3QgGSDu7J"
   },
   "source": [
    "def plot_middle_line_fft(img):\n",
    "    line = get_middle_line(img)\n",
    "    fft_vals = np.abs(np.fft.fft(line))\n",
    "    freq = np.fft.fftfreq(len(line))\n",
    "\n",
    "    plt.figure(figsize=(6, 2))\n",
    "    plt.plot(freq[:len(freq)//2], fft_vals[:len(freq)//2])  # partie positive\n",
    "    plt.title(\"FFT du profil de la ligne médiane\")\n",
    "    plt.xlabel(\"Fréquence\")\n",
    "    plt.ylabel(\"Amplitude\")\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "lxZSfyrSDu7K",
    "outputId": "614598bf-345d-4578-ab8f-f0186bb4358d"
   },
   "source": [
    "img = Xtrain[42][0]  # par exemple\n",
    "\n",
    "# Affiche l'image\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.title(\"Image choisie (idx=42)\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Affiche le profil + FFT\n",
    "plot_middle_line(img)\n",
    "plot_middle_line_fft(img)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "oHogEFJ0Du7K"
   },
   "source": [
    "def analyze_fft_profile(profile):\n",
    "    \"\"\"Analyse la FFT du profil : retourne l'énergie, le ratio haute/basse fréquence et le spectre\"\"\"\n",
    "    fft_vals = np.abs(np.fft.fft(profile))\n",
    "    fft_vals = fft_vals[:len(fft_vals) // 2] # Keep only real part\n",
    "\n",
    "    energy = np.sum(fft_vals ** 2)\n",
    "    low_freq_energy = np.sum(fft_vals[:5] ** 2)\n",
    "    high_freq_energy = np.sum(fft_vals[-10:] ** 2)\n",
    "    ratio_high_low = high_freq_energy / (low_freq_energy + 1e-6)\n",
    "\n",
    "    return energy, ratio_high_low, np.max(fft_vals)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "mmRmBQpxDu7K",
    "outputId": "a917f591-cca7-4d7c-948b-3e6347a8b349"
   },
   "source": [
    "energy_list = []\n",
    "ratio_list = []\n",
    "peak_list = []\n",
    "\n",
    "# Utilise un sous-échantillon pour accélérer (optionnel)\n",
    "for img in Xtrain[:1000, 0]:  # Shape = (N, 48, 48)\n",
    "    profile = get_middle_line(img)\n",
    "    energy, ratio, peak = analyze_fft_profile(profile)\n",
    "    energy_list.append(energy)\n",
    "    ratio_list.append(ratio)\n",
    "    peak_list.append(peak)\n",
    "\n",
    "# --- Tracé 3D ---\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(energy_list, ratio_list, peak_list, c='blue', alpha=0.6)\n",
    "ax.set_xlabel(\"Énergie totale du profil\")\n",
    "ax.set_ylabel(\"Ratio hautes/basses fréquences\")\n",
    "ax.set_zlabel(\"Pic FFT\")\n",
    "ax.set_title(\"Distribution des images selon leur profil spectral\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def normalize_images_contrast(images):\n",
    "    \"\"\"\n",
    "    Normalise le contraste de chaque image pour qu'elle occupe toute la plage [0, 255].\n",
    "    images : tableau numpy (N, 48, 48) ou (N, 1, 48, 48)\n",
    "    Retourne : tableau numpy (même shape), dtype uint8\n",
    "    \"\"\"\n",
    "    # Gérer les images avec canal unique (N, 1, H, W)\n",
    "    if images.ndim == 4 and images.shape[1] == 1:\n",
    "        images = images[:, 0]  # (N, H, W)\n",
    "\n",
    "    normed = np.empty_like(images, dtype=np.uint8)\n",
    "\n",
    "    for i, img in enumerate(images):\n",
    "        min_val = img.min()\n",
    "        max_val = img.max()\n",
    "        if max_val > min_val:\n",
    "            scaled = (img - min_val) / (max_val - min_val) * 255\n",
    "        else:\n",
    "            scaled = np.zeros_like(img)\n",
    "        normed[i] = scaled.astype(np.uint8)\n",
    "\n",
    "    return normed\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "Xtrain_norm = normalize_images_contrast(Xtrain)\n",
    "\n",
    "energy_list = []\n",
    "ratio_list = []\n",
    "peak_list = []\n",
    "\n",
    "# Utilise un sous-échantillon pour accélérer (optionnel)\n",
    "for img in Xtrain[:1000, 0]:  # Shape = (N, 48, 48)\n",
    "    profile = get_middle_line(img)\n",
    "    energy, ratio, peak = analyze_fft_profile(profile)\n",
    "    energy_list.append(energy)\n",
    "    ratio_list.append(ratio)\n",
    "    peak_list.append(peak)\n",
    "\n",
    "# --- Tracé 3D ---\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(energy_list, ratio_list, peak_list, c='blue', alpha=0.6)\n",
    "ax.set_xlabel(\"Énergie totale du profil\")\n",
    "ax.set_ylabel(\"Ratio hautes/basses fréquences\")\n",
    "ax.set_zlabel(\"Pic FFT\")\n",
    "ax.set_title(\"Distribution des images selon leur profil spectral\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib\n",
    "\n",
    "matplotlib.pyplot.close()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nvGTQaVNbLwI"
   },
   "source": [
    "#### Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YtCBe8TTbLwJ"
   },
   "source": [
    "Votre description ici"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n6zEsUpObLwJ"
   },
   "source": [
    "## 2b: Prétraitement des images\n",
    "\n",
    "**Point de départ:** *fer2013-clean.csv*\n",
    "\n",
    "Il y a différents types de prétraitement que nous pouvons appliquer à des images dans les ensembles de données pour réduire la variabilité, réduire des bruits, etc.\n",
    "\n",
    "En particulier, pour les images de visage, quelques prétraitements peuvent se montrer utiles, comme:\n",
    "- Localisation/recadrage du visage.\n",
    "- Localisation les yeux.\n",
    "- Lissage du visage.\n",
    "- Normalisation du contraste.\n",
    "- Etc.\n",
    "\n",
    "###  <font color=blue> À faire: </font>\n",
    "\n",
    "1. Appliquer au moins un prétraitement sur les images de visages. Vous pouvez choisir différents algorithmes de prétraitement d’images dans [scikit-image](https://scikit-image.org/docs/stable/api/api.html). Vous pouvez aussi trouver d’autres types de prétraitement qui sont plus généraux dans [scikit-learn](https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing).\n",
    "2. Appliquer ce/ces algorithmes sur les ensembles d’apprentissage et validation. Attention! Étant donné que les données de l'ensemble de test sont considérées \"inconnues\" préalablement, il faut à nouveau bien réfléchir quoi faire avec ces données pour ne pas biaiser vos resultats, voir les rendre faux!\n",
    "3. Générer un fichier *fer2013-clean-pre.csv* (même format) avec les données après le pretraitement.\n",
    "\n",
    "4. Expliquer et justifier le prétraitement utilisé.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wciKQWGhbLwJ"
   },
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ZsZYZ2sdbLwJ"
   },
   "source": [
    "# Votre code ici"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xBWoXEvXbLwJ"
   },
   "source": [
    "#### Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DU3q6VstbLwJ"
   },
   "source": [
    "Votre description ici"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N-36QvvpbLwJ"
   },
   "source": [
    "# Partie 3 - Classification\n",
    "\n",
    "**Point de départ:** *fer2013-clean-pre.csv*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5eAf4j4ZbLwJ"
   },
   "source": [
    "## 3a: Créer et évaluer une approche *template matching*\n",
    "\n",
    "Un algorithme simple de classification consiste à calculer un modèle (gabarit/prototype/*template*) sur les données d'apprentissage, pour chaque classe (7 émotions = 7 modèles) et utiliser ces modèles (prototypes) pour faire des prédictions sur de nouvelles données.\n",
    "\n",
    "Si les entrées ont toutes la même dimensionnalité (48x48), une façon très simple de calculer un modèle serait à partir du calcul des moyennes des valeurs de pixels) pour chaque classe.\n",
    "\n",
    "Étant donné un prototype pour chaque classe (7 prototypes), nous pouvons classifier une nouvelle entrée (image de visage) en mesurant la distance (similarité ou dissimilarité) de telle image par rapport aux sept prototypes et en choisissant le prototype (la classe du prototype) le plus proche."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UwSnWL8WbLwJ"
   },
   "source": [
    "###  <font color=blue> À faire: </font>\n",
    "1. Créer un *template*/gabarit/prototype pour chaque classe (émotion) depuis *fer2013-clean-pre.csv*\n",
    "2. Afficher chaque prototype (visage moyen pour chaque classe)\n",
    "3. Classifier par *template matching* (plus proche prototype), tous les exemples des ensembles d'apprentissage, validation et test) et rapporter les résultats suivants:<br>\n",
    "3a. Rapport de classification produit avec *<font color=green>from sklearn.metrics import classification_report</font>*<br>\n",
    "3b. taux de classification correct sur les trois (3) ensembles de données (sous la forme d'un tableau)<br>\n",
    "3c. matrice de confusion produite avec *<font color=green> from sklearn.metrics import confusion_matrix</font>* pour les résultats sur l'ensemble de test (matrice 7 x 7 - étiquette x prédictions)\n",
    "4. Faire une analyse des résultats et présenter vos conclusions sur l'approche *template matching* (Performance globale bonne/mauvaise, pourquoi? Performance par classe bonne/mauvaise pourquoi? Faiblesses et points fort, possibles améliorations, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lWgVoPplbLwJ"
   },
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "mwgShWPQbLwJ"
   },
   "source": [
    "# Votre code ici"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "miqJAGFVbLwJ"
   },
   "source": [
    "#### Résultats et réponses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8v6NAW1CDK3I"
   },
   "source": [
    "Vos réponses ici"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bxnlw_O0bLwJ"
   },
   "source": [
    "Taux de classification (%) - Exemple:\n",
    "\n",
    "| Ensemble | Modèle TM   |                   \n",
    "|----------|-------------|\n",
    "| Train      | 99,67       |                   \n",
    "| Val      | 89,77       |                             \n",
    "| Test     | 77,99       |        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3rgin1RlbLwP"
   },
   "source": [
    "# Partie 4 - Étude d'ablation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0460iy-qbLwQ"
   },
   "source": [
    "Point de départ: *fer2013-clean.csv*\n",
    "\n",
    "Dans l'apprentissage machine, l'ablation est la suppression d'un composant d'un système d'apprentissage machine. Une étude d'ablation étudie les performances d'un système d'apprentissage machine en supprimant certains composants pour comprendre la contribution du composant au système global.\n",
    "\n",
    "Alors, vous devez évaluer l'importance/contribution du prétraitement sur la performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D2L-toUxbLwQ"
   },
   "source": [
    "###  <font color=blue> À faire: </font>\n",
    "**Important: Aucun code requis pour la partie 4. Présentezr juste les résultats sous la forme d'un tableau comparatif.**\n",
    "1. Refaire la Partie 3 avec *fer2013-clean.csv*\n",
    "2. Rapportez les résultats suivants:<br>\n",
    "2a. taux de classification correct sur les trois (3) ensembles de données (sous la forme d'un tableau)<br> 2b. matrice de confusion pour les résultats sur l'ensemble de test (matrice 7 x 7 - étiquettes x prédictions)\n",
    "3. Faire une analyse des résultats et présenter vos conclusions sur l'importance du prétraitement.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iLirtyA_bLwQ"
   },
   "source": [
    "#### Code\n",
    "Aucun code requis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gJ6bW1iTbLwQ"
   },
   "source": [
    "#### Résultats et résponses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5uYIg1tZbLwQ"
   },
   "source": [
    "Taux de classification correcte modèle TM (%)\n",
    "\n",
    "\n",
    "| Ensemble | Avec prétraitement | Sans prétraitement |                                 \n",
    ":-|:-:|-:\n",
    "| App      |  99,67%       |   XX,XX%      |                   \n",
    "| Val      |  89,77%       |   XX,XX%      |                             \n",
    "| Test     |  77,99%       |   XX,XX%      |        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WzYHFej-bLwQ"
   },
   "source": [
    "# Fin"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
