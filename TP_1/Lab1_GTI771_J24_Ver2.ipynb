{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IamMoShi/GTI771-IA-TPs/blob/main/Lab1_GTI771_J24_Ver2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjgFUch8bLwE"
      },
      "source": [
        "# GTI771 - Apprentissage machine avancé\n",
        "## Département de génie logiciel et des technologies de l’information (LogTI)\n",
        "\n",
        "\n",
        "\n",
        "## Laboratoire 1 - Préparation des données\n",
        "#### <font color=black> Version 2 - Janvier 2024 </font>\n",
        "\n",
        "##### <font color=grey> Version 1 - Prof. Alessandro L. Koerich.\n",
        "##### Version 2 - Chargé de lab. Arthur Josi"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Les laboratoires sont à faire par groupe de deux ou trois étudiants. Favorisez les groupes de trois."
      ],
      "metadata": {
        "id": "1G_KivoknmxT"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSx7LnYLbLwG"
      },
      "source": [
        "| NOMS                  | CODE PERMANENT                                   |\n",
        "|-----------------------|--------------------------------------------------|\n",
        "| Étudiant1             | Code1                                            |\n",
        "| Étudiant2             | Code2                                            |\n",
        "| Étudiant3             | Code3                                            |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuR8ueyebLwG"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "Ce premier laboratoire porte sur la préparation de données pour l'apprentissage machine. Le problème de classification qui vous est présenté est le problème [Facial Expression Recognition (FER)](https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge/data), dont le but est de classer des visages dans sept catégories.\n",
        "\n",
        "Veuillez noter que les images qui vous sont fournies ne sont pas nécessairement très faciles à travailler. Plusieurs images comportent du bruit, des artéfacts ou des éléments non pertinents. Le défi de ce laboratoire repose sur cette difficulté qui est chose courante dans les problèmes d’apprentissage machine moderne.\n",
        "\n",
        "Voici, en exemple, des images de visages se retrouvant dans l’ensemble de données:\n",
        "\n",
        "![Exemples de FER](https://miro.medium.com/max/2420/1*nXqJ4lMiBRp4Ilm3bpRxuA.png)\n",
        "\n",
        "L’évaluation de ce laboratoire sera basée sur:\n",
        "- la qualité des algorithmes proposés et utilisés;\n",
        "- les réponses aux questions dans ce notebook;\n",
        "- l'organisation de votre code source (SVP, n'oubliez pas de mettre des commentaires dans le code source!)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "nb5c_PGPbLwG"
      },
      "source": [
        "# Modules et bibliotèques python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPZudkRhbLwG"
      },
      "source": [
        "### Import de bibliotèques"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNG3ZDNYbLwG"
      },
      "source": [
        "###  <font color=blue> À faire: </font>\n",
        "N'oubliez pas d'ajouter une courte description aux bibliothèques que vous allez utiliser pour compléter ce notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqWHnNHmbLwH",
        "jupyter": {
          "is_executing": true
        }
      },
      "source": [
        "import numpy as np  # package for scientific computing with Python.\n",
        "import matplotlib.pyplot as plt # 2D plotting library"
      ],
      "outputs": [],
      "execution_count": 2
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rsy-BvW3bLwH"
      },
      "source": [
        "# Partie 1 - Analyse exploratoire des données\n",
        "\n",
        "On va commencer par regarder les données, c'est une pratique indispensable.\n",
        "\n",
        "Pour ce lab, nous allons utiliser le dataset Facial Emotion Recognition (FER).\n",
        "\n",
        "L'ensemble de données est disponible dans Moodle. Il contient presque 35,000 images de visages, avec une résolution de 48$\\times$48 pixels en niveau de gris.\n",
        "\n",
        "Les images se trouvent dans un fichier csv sous la forme d’un vecteur de 2,304 scalaires avec des valeurs entre 0 et 255.\n",
        "\n",
        "Les partitions apprentissage, validation et test sont déjà préétablies.\n",
        "\n",
        "Format du fichier: Emotion,Pixels,Usage avec:\n",
        "- Emotion:  integer [0, 6]\n",
        "- Pixels:   integer [0, 255]\n",
        "- Usage:    string [Training, PublicTest, PrivateTest]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfrgTZ-jbLwI"
      },
      "source": [
        "## Charger le fichier de données"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "7SjPjCNoseu4",
        "outputId": "0d494880-5c48-4f43-b575-57862eb0df1e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-771dffc1-c77e-4e78-8ded-dfcce0f4e25e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-771dffc1-c77e-4e78-8ded-dfcce0f4e25e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving fer2013.csv to fer2013 (1).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "1X9PDGfruoSO",
        "outputId": "494e3e05-139d-473b-ff13-c58baf3aee63"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-d5df0069828e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    135\u001b[0m   )\n\u001b[1;32m    136\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdCmTZ-hbLwI",
        "jupyter": {
          "is_executing": true
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "outputId": "2eb2a58e-7ef0-44ac-8421-bfca7d47cb85"
      },
      "source": [
        "# Load data\n",
        "ferData = np.loadtxt('/content/fer2013.csv', delimiter=',', dtype=str)\n",
        "\n",
        "\n",
        "# Training partition\n",
        "Xtrain = np.ones( (28709,2304), float )\n",
        "\n",
        "for i in range( 1, 28710 ):\n",
        "    Xtrain[i-1] = ferData[i,1].split(\" \")\n",
        "\n",
        "ytrain = ferData[1:28710,0].astype( int )\n",
        "\n",
        "# Validation partition\n",
        "Xval = np.ones( (3589,2304), float )\n",
        "\n",
        "for i in range( 28710, 32299 ):\n",
        "    Xval[i-28710] = ferData[i,1].split(\" \")\n",
        "\n",
        "yval = ferData[28710:32299,0].astype( int )\n",
        "\n",
        "# Test partition\n",
        "Xtest = np.ones( (3589,2304), float )\n",
        "\n",
        "for i in range( 32299, 35887 ):\n",
        "    Xtest[i-32299] = ferData[i,1].split(\" \")\n",
        "\n",
        "ytest = ferData[32299:,0].astype( int )\n",
        "\n",
        "print(Xtrain.shape, Xval.shape, Xtest.shape)"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "UnicodeDecodeError",
          "evalue": "'utf-8' codec can't decode byte 0x92 in position 11: invalid start byte",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-7edc1b071058>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mferData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/fer2013.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Training partition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/lib/_npyio_impl.py\u001b[0m in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows, quotechar, like)\u001b[0m\n\u001b[1;32m   1379\u001b[0m         \u001b[0mdelimiter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1381\u001b[0;31m     arr = _read(fname, dtype=dtype, comment=comment, delimiter=delimiter,\n\u001b[0m\u001b[1;32m   1382\u001b[0m                 \u001b[0mconverters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconverters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskiplines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskiprows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musecols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1383\u001b[0m                 \u001b[0munpack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mndmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/lib/_npyio_impl.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(fname, delimiter, comment, quote, imaginary_unit, usecols, skiplines, max_rows, converters, ndmin, unpack, dtype, encoding)\u001b[0m\n\u001b[1;32m   1047\u001b[0m                     \u001b[0mchunk_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_loadtxt_chunksize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_rows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1049\u001b[0;31m                 next_arr = _load_from_filelike(\n\u001b[0m\u001b[1;32m   1050\u001b[0m                     \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdelimiter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcomment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquote\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquote\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m                     \u001b[0mimaginary_unit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimaginary_unit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n",
            "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0x92 in position 11: invalid start byte"
          ]
        }
      ],
      "execution_count": 3
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NhwicuG-bLwI"
      },
      "outputs": [],
      "source": [
        "# Reshape les vecteurs de 2,304 dimensions vers matrices 48x48\n",
        "# Afin d'avoir [samples][channels][width][height]\n",
        "\n",
        "Xtrain = Xtrain.reshape( Xtrain.shape[0], 1, 48, 48 ).astype('uint8')\n",
        "Xtest  = Xtest.reshape( Xtest.shape[0], 1, 48, 48 ).astype('uint8')\n",
        "Xval   = Xval.reshape( Xval.shape[0], 1, 48, 48 ).astype('uint8')\n",
        "\n",
        "print( Xtrain.shape, Xval.shape, Xtest.shape )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OuwIsZObLwI"
      },
      "source": [
        "## <font color=black> 1a: Visualisation des images de visages </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CyUZbsrybLwI"
      },
      "source": [
        "###  <font color=blue> À faire: </font>\n",
        "\n",
        "1. Créer une grille de dimension 7 lignes $\\times$ $4$ colones avec des images de visage prises aleatoirement dans l'ensemble de apprentissage. Montrer une catégorie dans chaque ligne.\n",
        "\n",
        "Vous pouvez visualiser les images en utilisant `plt.imshow`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vgZgFvmMbLwI"
      },
      "outputs": [],
      "source": [
        "# Votre code ici\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zov3P0A_bLwI"
      },
      "source": [
        "## 1b: Statistiques des données"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jB7A3jjXbLwI"
      },
      "source": [
        "Est-ce que vous avez un ensemble de données balancé? C.-à-d., une distribution égalitaire d’exemples par classe?\n",
        "\n",
        "###  <font color=blue> À faire: </font>\n",
        "\n",
        "1. Montrer les histogrammes de distribution des données pour les partitions de validation et test."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30s0INznbLwI"
      },
      "source": [
        "#### Code"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Code exemple pour la base d'entrainement:\n",
        "\n",
        "# Histogramme des étiquettes (classes) - Apprentissage\n",
        "hist, _ = np.histogram(ytrain, density=False, bins=7, range=(0, 7))\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "ax.hist(ytrain, bins = [0,1,2,3,4,5,6,7])\n",
        "\n",
        "ax.set_xticklabels([])\n",
        "#(0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral).\n",
        "labels = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
        "mticks = ax.get_xticks()\n",
        "ax.set_xticks([0.5, 1.5, 2.5, 3.5, 4.5, 5.5, 6.5], minor=True)\n",
        "ax.tick_params(axis='x', which='minor', length=0)\n",
        "ax.set_xticklabels(labels, minor=True)\n",
        "plt.show()\n",
        "\n",
        "### Votre code ici pour validation et test\n",
        "\n"
      ],
      "metadata": {
        "id": "uTH-ZdIYwHg0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nA7XzrAfbLwI"
      },
      "source": [
        "# Partie 2 - Préparation des données"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZ43VPmNbLwI"
      },
      "source": [
        "## 2a: Nettoyage et normalisation des données"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BeIyURjjbLwI"
      },
      "source": [
        "Avant de passer à d'autres étapes, vous devez vous assurer que il n'y a pas de:\n",
        "- données abberantes;\n",
        "- valeurs manquantes;\n",
        "- valeurs inapplicables ou aberrantes;\n",
        "- etc.   \n",
        "\n",
        "###  <font color=blue> À faire: </font>\n",
        "\n",
        "1. Concevoir un algorithme pour vérifier l'intégrité des données, faire des corrections si nécessaires, et finalement, normaliser les données dans la plage [0, 1].\n",
        "2. Appliquer sur les ensembles d’apprentissage et validation. Attention! Étant donné que les données de l'ensemble de test sont considérées \"inconnues\" préalablement, il faut bien réfléchir quoi faire avec ces données.\n",
        "3. Générer un fichier *fer2013-clean.csv* (même format) avec les données nettoyées et normalisées.\n",
        "\n",
        "4. Décrire les étapes de votre algorithme/code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlMIVtypbLwJ"
      },
      "source": [
        "#### Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IdQsDBLTbLwJ"
      },
      "outputs": [],
      "source": [
        "# Votre code ici\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvGTQaVNbLwI"
      },
      "source": [
        "#### Description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtCBe8TTbLwJ"
      },
      "source": [
        "Votre description ici"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6zEsUpObLwJ"
      },
      "source": [
        "## 2b: Prétraitement des images\n",
        "\n",
        "**Point de départ:** *fer2013-clean.csv*\n",
        "\n",
        "Il y a différents types de prétraitement que nous pouvons appliquer à des images dans les ensembles de données pour réduire la variabilité, réduire des bruits, etc.\n",
        "\n",
        "En particulier, pour les images de visage, quelques prétraitements peuvent se montrer utiles, comme:\n",
        "- Localisation/recadrage du visage.\n",
        "- Localisation les yeux.\n",
        "- Lissage du visage.\n",
        "- Normalisation du contraste.\n",
        "- Etc.\n",
        "\n",
        "###  <font color=blue> À faire: </font>\n",
        "\n",
        "1. Appliquer au moins un prétraitement sur les images de visages. Vous pouvez choisir différents algorithmes de prétraitement d’images dans [scikit-image](https://scikit-image.org/docs/stable/api/api.html). Vous pouvez aussi trouver d’autres types de prétraitement qui sont plus généraux dans [scikit-learn](https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing).\n",
        "2. Appliquer ce/ces algorithmes sur les ensembles d’apprentissage et validation. Attention! Étant donné que les données de l'ensemble de test sont considérées \"inconnues\" préalablement, il faut à nouveau bien réfléchir quoi faire avec ces données pour ne pas biaiser vos resultats, voir les rendre faux!\n",
        "3. Générer un fichier *fer2013-clean-pre.csv* (même format) avec les données après le pretraitement.\n",
        "\n",
        "4. Expliquer et justifier le prétraitement utilisé.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wciKQWGhbLwJ"
      },
      "source": [
        "#### Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZsZYZ2sdbLwJ"
      },
      "outputs": [],
      "source": [
        "# Votre code ici"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBWoXEvXbLwJ"
      },
      "source": [
        "#### Description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DU3q6VstbLwJ"
      },
      "source": [
        "Votre description ici"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-36QvvpbLwJ"
      },
      "source": [
        "# Partie 3 - Classification\n",
        "\n",
        "**Point de départ:** *fer2013-clean-pre.csv*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5eAf4j4ZbLwJ"
      },
      "source": [
        "## 3a: Créer et évaluer une approche *template matching*\n",
        "\n",
        "Un algorithme simple de classification consiste à calculer un modèle (gabarit/prototype/*template*) sur les données d'apprentissage, pour chaque classe (7 émotions = 7 modèles) et utiliser ces modèles (prototypes) pour faire des prédictions sur de nouvelles données.\n",
        "\n",
        "Si les entrées ont toutes la même dimensionnalité (48x48), une façon très simple de calculer un modèle serait à partir du calcul des moyennes des valeurs de pixels) pour chaque classe.\n",
        "\n",
        "Étant donné un prototype pour chaque classe (7 prototypes), nous pouvons classifier une nouvelle entrée (image de visage) en mesurant la distance (similarité ou dissimilarité) de telle image par rapport aux sept prototypes et en choisissant le prototype (la classe du prototype) le plus proche."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwSnWL8WbLwJ"
      },
      "source": [
        "###  <font color=blue> À faire: </font>\n",
        "1. Créer un *template*/gabarit/prototype pour chaque classe (émotion) depuis *fer2013-clean-pre.csv*\n",
        "2. Afficher chaque prototype (visage moyen pour chaque classe)\n",
        "3. Classifier par *template matching* (plus proche prototype), tous les exemples des ensembles d'apprentissage, validation et test) et rapporter les résultats suivants:<br>\n",
        "3a. Rapport de classification produit avec *<font color=green>from sklearn.metrics import classification_report</font>*<br>\n",
        "3b. taux de classification correct sur les trois (3) ensembles de données (sous la forme d'un tableau)<br>\n",
        "3c. matrice de confusion produite avec *<font color=green> from sklearn.metrics import confusion_matrix</font>* pour les résultats sur l'ensemble de test (matrice 7 x 7 - étiquette x prédictions)\n",
        "4. Faire une analyse des résultats et présenter vos conclusions sur l'approche *template matching* (Performance globale bonne/mauvaise, pourquoi? Performance par classe bonne/mauvaise pourquoi? Faiblesses et points fort, possibles améliorations, etc.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWgVoPplbLwJ"
      },
      "source": [
        "#### Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mwgShWPQbLwJ"
      },
      "outputs": [],
      "source": [
        "# Votre code ici"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "miqJAGFVbLwJ"
      },
      "source": [
        "#### Résultats et réponses"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vos réponses ici"
      ],
      "metadata": {
        "id": "8v6NAW1CDK3I"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxnlw_O0bLwJ"
      },
      "source": [
        "Taux de classification (%) - Exemple:\n",
        "\n",
        "| Ensemble | Modèle TM   |                   \n",
        "|----------|-------------|\n",
        "| Train      | 99,67       |                   \n",
        "| Val      | 89,77       |                             \n",
        "| Test     | 77,99       |        \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rgin1RlbLwP"
      },
      "source": [
        "# Partie 4 - Étude d'ablation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0460iy-qbLwQ"
      },
      "source": [
        "Point de départ: *fer2013-clean.csv*\n",
        "\n",
        "Dans l'apprentissage machine, l'ablation est la suppression d'un composant d'un système d'apprentissage machine. Une étude d'ablation étudie les performances d'un système d'apprentissage machine en supprimant certains composants pour comprendre la contribution du composant au système global.\n",
        "\n",
        "Alors, vous devez évaluer l'importance/contribution du prétraitement sur la performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2L-toUxbLwQ"
      },
      "source": [
        "###  <font color=blue> À faire: </font>\n",
        "**Important: Aucun code requis pour la partie 4. Présentezr juste les résultats sous la forme d'un tableau comparatif.**\n",
        "1. Refaire la Partie 3 avec *fer2013-clean.csv*\n",
        "2. Rapportez les résultats suivants:<br>\n",
        "2a. taux de classification correct sur les trois (3) ensembles de données (sous la forme d'un tableau)<br> 2b. matrice de confusion pour les résultats sur l'ensemble de test (matrice 7 x 7 - étiquettes x prédictions)\n",
        "3. Faire une analyse des résultats et présenter vos conclusions sur l'importance du prétraitement.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLirtyA_bLwQ"
      },
      "source": [
        "#### Code\n",
        "Aucun code requis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJ6bW1iTbLwQ"
      },
      "source": [
        "#### Résultats et résponses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5uYIg1tZbLwQ"
      },
      "source": [
        "Taux de classification correcte modèle TM (%)\n",
        "\n",
        "\n",
        "| Ensemble | Avec prétraitement | Sans prétraitement |                                 \n",
        ":-|:-:|-:\n",
        "| App      |  99,67%       |   XX,XX%      |                   \n",
        "| Val      |  89,77%       |   XX,XX%      |                             \n",
        "| Test     |  77,99%       |   XX,XX%      |        \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzYHFej-bLwQ"
      },
      "source": [
        "# Fin"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}